### 8 服务器程序框架

* I/O处理单元：四种I/O模型和两种高效事件处理模式
* 逻辑单元。半同步、办异步模式。领导者追随者模式
* 高效的逻辑处理方式：有限状态机

#### 8.1 服务器模型

c/s模型

![image-20211213185754879](C:\Users\mzx\AppData\Roaming\Typora\typora-user-images\image-20211213185754879.png)

**p2p** 模型

peer to peer 模型。让所有主机回到对等位置。



#### 8.2 服务器编程框架

* I/O处理单元：处理客户连接，读写网络数据
* 逻辑单元，业务进程或线程
* 网络存储单元：本地数据库、文件或缓存
* 请求队列：各单元之间的通信方式。

#### 8.3 I/O模型

阻塞和非阻塞的概念能应用于所有文件描述符，而不仅仅是socket。将阻塞的文件描述符成为阻塞I/O。将非阻塞的文件描述符称为非阻塞I/O。

针对阻塞I/O执行的系统调用可能无法立即完成而被操作系统挂起，直到等待的时间发生为止。可能被阻塞的系统调用包括accept、send、recv、connect。

针对非阻塞I/O执行的系统调用总是立即返回，而不管时间是否已经发生。如果时间没有立即发生，这些系统调用就返回-1，和出错情况一样。根据errno来区分这两种情况。

所以只有在事件已经发生的情况下操作非阻塞I/O，才能提高程序的效率。因此非阻塞I/O通常要和其他I/O通知机制一起使用，比如I/O复用和SIGIO信号

* I/O复用是最常使用的I/O通知机制。应用程序用过复用函数向内核注册一组事件，内核通过I/O复用函数把其中就绪的事件通知给应用程序。常用的复用函数有 select，poll epoll_wait。I/O复用函数本身是阻塞的，他们能提高程序效率的原因在于他们具有同时监听多个I/O事件的能力
* SIGIO信号也可以用来报告I/O事件。信号的使用后面讲。

I/O模型对比

* 阻塞I/O：程序阻塞于读写函数
* I/O复用：程序阻塞于I/O复用系统调用，但可同时监听多个I/O事件。对I/O本身读写操作是非阻塞的
* SIGIO信号：信号出发读写就绪事件，用户程序执行读写操作。程序没有阻塞阶段
* 异步I/O:内核执行读写操作并出发读写完成事件。程序没有阻塞阶段

#### 8.4 高效时间处理模式

Reactor和Proactor，同步I/O模型常用于实现Reactor模式，异步I/O模型则用于实现Proactor模式。

##### 8.4.1 Reactor模式

要求主线程只负责监听文件描述符上是否有事件发生，有的话立即将该事件通知工作线程（逻辑单元）。除此之外，主线程不做任何其他实质性工作。读写数据，接受新的连接，以及处理客户请求均在工作线程中完成。

工作流程如下（以epoll_wait为例）

* 主线程epoll内核时间表中注册socket上的读就绪事件
* 主线程调用epoll_wait等待socket上有数据可读
* 当socket上有数据可读时，epoll_wait通知主线程，主线程则将socket可读事件放入请求队列。
* 睡眠在请求队列上的某个工作线程被唤醒，从socket读取数据，并处理客户请求，然后往epoll内核时间表中注册该socket上的写就绪事件

* 主线程调用epoll_wait等待socket可写
* 当socket可写时，epoll_wait通知主线程。主线程将socket可写事件放入请求队列。
* 睡眠在请求队列上的某个工作线程被唤醒，它往socket上写入服务器处理客户请求的结果。

![image-20211213192820198](C:\Users\mzx\AppData\Roaming\Typora\typora-user-images\image-20211213192820198.png)

工作线程从请求队列中取出事件后，将根据事件的类型来决定如何处理它：对于可读事件，执行读数据和处理请求的操作：对于可写事件，执行写数据的操作。因此没必要区分读工作线程和写工作线程。

**Proactor**模式

与Reactor模式不同。Proactor模式将所有I/O操作都交给主线程和内核来处理，工作线程仅仅负责业务逻辑。

使用异步I/O模型实现Proactor模式的工作流程（以aio_read和aio_write为例）

* 主线程调用aio_read函数向内核注册socket上的读完成事件。并告诉内核用户缓冲区的位置，以及操作完成时如何通知应用程序。
* 主线程继续处理其他逻辑
* 当socket上的数据被读入用户缓冲区后，内核将向应用程序发送一个信号，以通知应用程序数据已经可用。
* 应用程序预先定义好的信号处理函数选择一个工作线程来处理客户请求。工作线程处理完客户请求之后，调用aio_write函数向内核注册socket上的写完成事件，并告诉内核用户写缓冲区的位置，以及写操作完成时如何通知应用程序
* 主线程继续处理其他逻辑
* 当用户缓冲区数据被写入socket之后，内核将向应用程序发送一个信号，以通知应用程序数据已经发送完毕。
* 应用程序预先定义好的信号处理函数选择一个工作线程来做善后，比如决定是否关闭socket

![image-20211213194729096](C:\Users\mzx\AppData\Roaming\Typora\typora-user-images\image-20211213194729096.png)

连接socket上的读写事件是通过aio_read/aio_write向内核注册的，因此内核将通过信号来向应用程序报告连接socket上的读写事件。所以主线程中epoll_wait调用仅能用来检测监听socket上的连接请求事件，而不能用来检测连接socket上的读写事件。

**模拟Proactor模式**

使用同步I/O方式模拟出Proactor模式。原理是：主线程执行数据读写操作，读写完成之后，主线程向工作线程通知这一“完成事件”。那么从工作线程的角度来看，他们就直接获得了数据读写的结果，接下来要做的只是对读写的结果进行逻辑处理。

使用同步I/O模型（epoll_wait为例）模拟出Proactor模式的工作流程如下：

* 主线程往epoll内核事件表中注册socket上的读就绪事件。
* 主线程调用epoll_wait等待socket上有数据可读
* 当socket有数据可读时，epoll_wait通知主线程。主线程从socket循环读取数据，直到没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。
* 睡眠在请求队列上的某个工作线程被唤醒，他获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。
* 主线程调用epoll_wait等待socket可写
* 当socket可写时，epoll_wait通知主线程。主线程往socket上写入服务器处理客户请求的结果。

#### 8.5 两种高效的并发模式

并发编程的目的是让程序同时执行多个任务。如果程序是计算密集型的，并发编程并没有优势，反而由于任务的切换使效率降低。如果程序是I/O密集型的，比如经常读写文件，访问数据库等，则情况不同。由于I/O操作的速度远没有CPU的计算速度快，所以让程序阻塞于I/O操浪费大量的cpu时间。如果程序有多个执行线程则当前被I/O操作所阻塞的执行线程可主动放弃cpu，并将执行权转移到其他线程。这样一来，CPU就可以用来做更加有意义的事情。

并发模式是指I/O处理单元和多个逻辑单元之间协调完成任务的方法。

服务器主要有两种并发编程的模式

* 半同步/半异步模式
* 领导者/追随者模式

##### 8.5.1 半同步/半异步模式

这里的同步和异步与前面讨论的I/O模型中的同步和异步是完全不同的概念。在I/O模型中，同步异步区分的是内核向应用程序通知的是何种I/O事件（就绪事件还是完成事件），以及该由谁来完成I/O读写（应用程序还是内核）。

在并发模式中，同步指的是程序完全按照代码顺序执行。异步指的是程序的执行需要由系统事件来驱动。常见的系统事件包括中断、信号灯。

![image-20211213202654037](C:\Users\mzx\AppData\Roaming\Typora\typora-user-images\image-20211213202654037.png)

按照同步方式运行的线程成为同步线程，按照异步方式运行的线程成为异步线程。显然，异步线程的执行效率高，实时性强。但是编写异步方式执行的程序相对复杂，难于调试和扩展，而且不适合大量的并发。同步线程效率低，实时性差，但逻辑简单。因此像服务器这种应该使用半同步/办异步模式来实现。

在这种模式中，同步线程用于处理客户逻辑，相当于逻辑单元；异步线程用于处理I/O事件。异步线程监听到客户请求后，就将其封装成请求并插入请求队列中。请求队列将通知某个工作在同步模式的工作线程来读取并处理该请求对象。

半同步/半反应堆模式

![image-20211213203532046](C:\Users\mzx\AppData\Roaming\Typora\typora-user-images\image-20211213203532046.png)

异步线程只有一个，由主线程来充当。他负责监听所有socket事件。如果监听socket上有可读事件发生，即有新的连接请求到来，主线程就接受之以得到新的连接socket，然后往epoll内核时间表中注册该socket上的读写事件。如果连接socket上有读写事件发生，即有新的客户请求到来或数据要发送到客户端，主线程就将该连接socket插入请求队列中。所有工作线程都睡眠在请求队列上，当有任务到来时，他们将通过竞争获得任务的接管权。这种竞争机制使得只有空闲的工作线程才有机会来处理新任务，合理。



主线程插入请求队列中的任务是就绪的连接socket。这说明上图所示的半同步/办反应堆模式采用的时间处理模式是Reactor模式：要求工作线程从socket上读取客户请求和往socket写入服务器应答实际上，半同步/半反应堆模式也可以使用模拟的Proactor时间处理模式，即由主线程来完成数据的读写。在这种情况下，主线程一般会将应用程序数据、任务类型等信息封装成为一个任务对象，然后将其插入请求队列。工作线程从请求队列中取得任务对象之后，即可直接处理，而无须执行读写操作。

半同步半反应堆模式存在如下缺点

* 主线程和工作线程共享请求队列，主线程往请求队列中添加任务，或者工作线程从请求队列中取出任务，都需要对请求队列加锁保护，从而白白耗费cpu时间。
* 每个工作线程在同一时间只能处理一个客户请求。如果客户数量较多，而工作线程较少，则请求队列中将堆积很多任务对象，客户端的响应速度将越来越慢。如果通过增加工作线程来解决，则工作线程的切换也将耗费大量CPU时间。

下面一种相对高效的半同步/半异步模式，他的每个工作线程同时处理多个客户连接。

![image-20211213210500069](C:\Users\mzx\AppData\Roaming\Typora\typora-user-images\image-20211213210500069.png)

主线程只管监听socket，连接socket由工作线程来管理。当有新的连接到来时，主线程就接受之并将新返回的连接socket派发给某个工作线程，此后该新socket上的任何I/O操作都由被选中的工作线程来处理，直到客户关闭连接。主线程向工作线程派发socket的最简单的方式，是往它和工作线程之间的管道里写数据。工作线程检测到管道有数据可读时，就分析是否是一个新的客户连接请求到来。如果是就把该socket上的读写事件注册到自己的epoll内核时间表中。

##### 8.5.2 领导者、追随者模式

领导者/追随者模式是多个工作线程轮流获得事件源集合，轮流监听、分发并处理事件的一种模式。在任意时间点，程序都仅有一个领导者线程，他负责监听I/O事件。而其他线程则都是追随者，他们休眠在线程池中等待成为新的领导者。当前的领导者如果检测到I/O事件，首先要从线程池中推选出新的领导者线程，然后处理I/O事件。此时新的领导者等待新的I/O事件，而原来的领导者则处理I/O事件，二者实现了并发。

包含了几个组件：

* 句柄集：用于表示I/O资源，在linux下通常就是一个文件描述符。句柄集管理众多句柄，他使用wait_for_event方法来监听这些句柄的I/O事件，并将其中的就绪事件通知给领导者线程。领导者则调用绑定到Handle上的时间处理器来处理事件。领导者将Handle和事件处理器绑定是通过调用句柄集中register_handle方法实现的。

* 线程集：所有工作线程的管理者。负责各线程之间的同步，以及新领导者线程的推选。线程集中的线程在任一时间必处于三种状态之一

  * Leader：线程当前处于领导者身份，负责句柄集上的I/O事件
  * Processing：线程正在处理事件。领导者检测到I/O事件之后，可以转移到Processing状态来处理该事件，并调用promote_new_leader方法推选新的领导者；也可以指定其他追随者来处理事件，此时领导者的地位不变。当处于Processing状态的线程处理完事件之后，如果当前线程没有领导者，则它将成为新的领导者，否则它就直接转变为追随者。
  * Follower：当前处于追随者身份，通过调用线程集的join方法等待成为新的领导者，也可能被当前的领导者指定来处理新的任务。
  * ![image-20211213213434002](C:\Users\mzx\AppData\Roaming\Typora\typora-user-images\image-20211213213434002.png)

  他们三个的关系是这样的。

* 事件处理器：事件处理器通常包含一个或多个回调函数handle_event。这些回调函数用于处理事件对应的业务逻辑。使用前需要被绑定到某个句柄上，当该句柄上有事件发生时，领导者就执行与之绑定的事件处理器中的回调函数。

* 具体的时间处理器：是事件处理器的派生类。他们必须重新实现基类的handle_event方法，以处理特定的任务。

由于领导者线程自己监听I/O事件并处理客户请求，因而领导者/追随者模式不需要在线程之间传递任何额外的数据，也无须像半同步/办反应堆模式在线程之间同步对请求队列的访问。但领导者/追随者的一个明显缺点是仅支持一个事件源集合，因此无法让每个工作线程独管理多个客户连接。

#### 8.6 有限状态机

有的应用层协议头部包含数据包类型字段，每种类型可以映射为逻辑单元的一种状态，服务器可以根据它来编写响应的处理逻辑。

一个简单的小例子

```
STATE_machine(package pack){
	pacjageType type=pack.type();
	switch(type){
		case type_A:
			process_package_A(pack);
			break;
		case type_B:
			process_package_B(pack);
			break;
}
}
```

这只是一个简单的有限状态机，这里每个状态机之间都是相互独立的，即状态之间没有相互转移。状态之间的转移需要状态机内部驱动的。

下面这个才是状态机的正常状态：

```
state_machine(){
	state cur_state=type_A;
	while(cur_state!=type_C){
		package pack=getNewPackage();
		switch(cur_state){
			case type_A:
				process_package_state_A(pack);
				cur_state=type_B;
				break;
			case type_B:
				process_package_state_B(pack);
				cur_state=type_C;
				break;
		}
	}
}
```

这个状态机包含三种状态：A，B，C三种，A是状态机的初始状态，C是状态机的结束状态。状态机的当前状态在cur_state变量中。在这一趟循环过程中，状态机先通过getNewPackage方法获得一个新的数据报，然后根据cur_state变量的值判断如何处理该数据包。数据包处理完后，状态机通过给cur_state变量传递目标值来实现状态转移。那么当状态机进入下一个循环时，将执行新的状态对应的逻辑。

#### 池

池是一个以空间换时间的一种方法。是一种资源的集合，这组资源在服务器启动之初就被完全创建好并初始化，这称为静态资源分配。当服务器进入正式运行阶段，如果需要相关资源，就可以直接从池中获取，无须动态分配。当处理完一个客户连接后，可以把相关的资源放回池中，无须执行系统调用来释放资源。

池资源是预先静态分配的，无法预期该分配多少资源。分多了浪费资源，分少了不够用，所以可以预先分配一定的资源，之后发现资源不够用，就再动态分配一些并加入池中。

池可以分为很多类：

* 进程池：当使用的时候直接取，不需要使用fork来创建（浪费时间）
* 内存池：通常用于socket接收缓存和发送缓存。
* 线程池：这个也是用的时候直接取，不需要使用pthread_create来创建
* 连接池：通常用于服务器或服务器集群的内部永远连接。

##### 数据复制

避免不必要的数据复制，尤其是当数据复制发生在用户代码和内核之间的时候。如果内核可以直接处理socket或者文件读入的数据，则应用程序就没必要将这些数据从内核缓冲区复制到应用程序缓冲区中。

##### 上下文切换和锁

并发程序必须考虑上下文切换问题，即进程切换或线程切换导致的系统开销。切换会导致大量的开销。

锁是导致服务器效率低下的一个因素，因为它引入的代码不仅不处理任何业务逻辑，还需要访问内核资源，因此应该避免锁。
